# Robot:UR5

- [VIMA](https://github.com/youliangtan/oxe_contrib/tree/main/pages/datasets/vima.md): The robot is conditioned on multimodal prompts (mixture of texts, images, and video frames) to conduct tabletop manipulation tasks, ranging from rearrangement to one-shot imitation.
- [Columbia_PushT_Dataset](https://github.com/youliangtan/oxe_contrib/tree/main/pages/datasets/columbia_cairlab_pusht_real.md): The robot pushes a T-shaped block into a fixed goal pose, and then move to an fixed exit zone.
- [Berkeley_Autolab_UR5](https://github.com/youliangtan/oxe_contrib/tree/main/pages/datasets/berkeley_autolab_ur5.md): The data consists of 4 robot manipulation tasks: simple pick-and-place of a stuffed animal between containers, sweeping a cloth, stacking cups, and a more difficult pick-and-place of a bottle that requires precise grasp and 6DOF rotation
- [ASU_TableTop_Manipulation](https://github.com/youliangtan/oxe_contrib/tree/main/pages/datasets/asu_table_top_converted_externally_to_rlds.md): The robot interacts with a few objects on a table. It picks up, pushes forward, or rotates the objects.